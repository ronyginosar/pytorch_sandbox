{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSvpz8VI89uThq8B/wQYq0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DO4sLYCWhILM"},"outputs":[],"source":["# Mout Google Drive\n","# https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228\n","from google.colab import drive\n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n","# %pwd %ls\n","# run github settings\n","%run /content/drive/MyDrive/CNNStanford/pytorch/pytorch_sandbox/Colab_Helper.ipynb"]},{"cell_type":"code","source":["MESSAGE = \"clean file & gitignore again\"\n","!git config --global user.email \"ronyginosar@mail.huji.ac.il\"\n","!git config --global user.name \"ronyginosar\"\n","!git add ."],"metadata":{"id":"A6ENAdliiQ9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"{MESSAGE}\"\n","!git push \"{GIT_PATH}\""],"metadata":{"id":"9QWMKhNdiTJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchinfo import summary\n","import sys\n","from torchvision import transforms\n","\n","#%%\n","# Optional additions:\n","# ‘Valid’ [default]  vs. ‘Same’ padding:\n","#   https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n","# (not in original breif):\n","# feature_channels an enum and input\n","# 'depth' input for easier size changes\n","# module list using depth to create down and up directions, rather than code repetition, e.g.:\n","#  self.down_path = nn.ModuleList()\n","#         for i in range(depth):\n","#             self.down_path.append(\n","#                 UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n","#             )\n","#             prev_channels = 2 ** (wf + i)\n","\n","#%%\n","\n","# Implement UNet as a nn Module\n","class UNet(nn.Module):\n","    \"\"\"\n","    U-Net: Convolutional Networks for Biomedical Image Segmentation (Ronneberger et al., 2015)\n","    https://arxiv.org/abs/1505.04597\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels=1,\n","                 out_channels=2,\n","                 up_mode='upconv'\n","                 ):\n","        super().__init__()\n","        # Support any number of output classes, input channels, 'depth'...\n","        feature_channels = 64\n","\n","        # Support Transposed Convolutions [default] vs. Bilinear upscaling\n","        assert up_mode in ('upconv', 'upsample')\n","        bilinear = False\n","        if up_mode == 'upsample':   bilinear = True\n","        elif up_mode == 'upconv':   bilinear = False\n","\n","        # submodules:\n","        # conv 3*3 , Relu => *2\n","        self.in_block = conv_relu_2(in_channels, out_channels=feature_channels)\n","        # downsampling maxpool, at each downsampling step we double the number of feature channels\n","        self.down1 = maxpool(in_channels=feature_channels, out_channels=feature_channels*2)  # 64,128\n","        feature_channels *= 2\n","        self.down2 = maxpool(in_channels=feature_channels, out_channels=feature_channels*2)  # 128,256\n","        feature_channels *= 2\n","        self.down3 = maxpool(in_channels=feature_channels, out_channels=feature_channels*2)  # 256, 512\n","        feature_channels *= 2\n","        self.down4 = maxpool(in_channels=feature_channels, out_channels=feature_channels*2)  # 512, 1024\n","        feature_channels *= 2\n","\n","        # copy and crop & up-conv 2*2\n","        self.up1 = UpNConcat(feature_channels, bilinear)\n","        feature_channels //= 2\n","        self.up2 = UpNConcat(feature_channels, bilinear)\n","        feature_channels //= 2\n","        self.up3 = UpNConcat(feature_channels, bilinear)\n","        feature_channels //= 2\n","        self.up4 = UpNConcat(feature_channels, bilinear)\n","        feature_channels //= 2\n","\n","        # conv 1*1\n","        self.out = out_conv(in_channels=feature_channels, out_channels=out_channels)  # 64, 2\n","\n","    def forward(self, x):\n","        x1 = self.in_block(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)   # bottom\n","        x = self.up1(x4, x5)  # to_copy, to_up_append\n","        x = self.up2(x3, x)\n","        x = self.up3(x2, x)\n","        x = self.up4(x1, x)\n","        out = self.out(x)\n","        return out\n","\n","\n","#%% Sequentials\n","\n","def conv_relu_2(in_channels, out_channels, *args, **kwargs):\n","    \"\"\"pair of (convolution => ReLU)\n","    repeated application of two 3x3 convolutions (unpadded convolutions), each followed by\n","    a rectified linear unit (ReLU)\"\"\"\n","    return nn.Sequential(conv_relu(in_channels, out_channels, *args, **kwargs),\n","                         conv_relu(out_channels, out_channels, *args, **kwargs)\n","                         )\n","\n","\n","def maxpool(in_channels, out_channels, kernel_size=2, *args, **kwargs):\n","    \"\"\"max pool 2*2 (down) followed by pair of (convolution => ReLU)\n","    2x2 max pooling operation with stride 2 for downsampling\"\"\"\n","    return nn.Sequential(nn.MaxPool2d(kernel_size),\n","                         conv_relu_2(in_channels, out_channels, *args, **kwargs)\n","                         )\n","\n","\n","def up_conv(in_channels, out_channels):\n","    \"\"\"upsampling of the feature map followed by a 2x2 convolution (up-convolution) that halves the\n","    number of feature channels\"\"\"\n","    return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n","\n","\n","def out_conv(in_channels, out_channels, *args, **kwargs):\n","    \"\"\"At the final layer a 1x1 convolution is used to map each 64-component\n","     feature vector to the desired number of classes.\"\"\"\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=1, *args, **kwargs)\n","\n","\n","#%% base module of a 3x3 convolution (unpadded convolutions), followed by a (ReLU)\n","def conv_relu(in_channels, out_channels, *args, **kwargs):\n","    \"\"\"(convolution => ReLU)\n","    base module of a 3x3 convolution (unpadded convolutions), followed by a (ReLU)\"\"\"\n","    return nn.Sequential(nn.Conv2d(in_channels, out_channels, padding=0, kernel_size=3, *args, **kwargs),\n","                         nn.ReLU()\n","                         )\n","\n","#%% Classes\n","\n","class UpNConcat(nn.Module):\n","    \"\"\"upsampling of the feature map followed by a 2x2 convolution (up-convolution) that halves the\n","    number of feature channels, a concatenation with the correspondingly cropped\n","    feature map from the contracting path, and two 3x3 convolutions, each fol-\n","    lowed by a ReLU.\n","    The cropping is necessary due to the loss of border pixels in every convolution.\n","    \"\"\"\n","    def __init__(self, feature_channels, bilinear=False):\n","        super().__init__()\n","        # upsample input\n","        if bilinear:  # if bilinear, use the normal convolutions to reduce the number of channels\n","            self.up = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n","                                    nn.Conv2d(in_channels=feature_channels,\n","                                              out_channels=(feature_channels//2), kernel_size=1))\n","        else:  # learning version\n","            self.up = up_conv(in_channels=feature_channels, out_channels=(feature_channels//2))\n","        # after crop and concat - double conv\n","        self.conv = conv_relu_2(in_channels=feature_channels, out_channels=(feature_channels//2))\n","\n","    def forward(self, to_copy, to_up_append):\n","        # upsample input to_append\n","        upsampled = self.up(to_up_append)\n","        '''\n","        optional:\n","        # pad upsampled to match to_copy (which is a tad larger), rather than crop larger (very unclear grammar):\n","        the original paper encourage down-sampling without padding the same as the up-sampling without zero-padding, \n","        which can avoid corrupting semantic information. \n","        This is the one of the reason for which the overlap-tile strategy was proposed\n","        https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n","        '''\n","        # crop to_copy\n","        x_dim = 2; y_dim = 3\n","        H, W = upsampled.size()[x_dim], upsampled.size()[y_dim]\n","        cropped_copy = transforms.CenterCrop([H, W])(to_copy)  # from: https://amaarora.github.io/2020/09/13/unet.html\n","        # concat\n","        cat_out = torch.cat([cropped_copy, upsampled], dim=1)\n","        # double conv\n","        out = self.conv(cat_out)\n","        return out\n","\n","#%%\n","def main(argv):\n","\n","    # Create a net instance\n","    net = UNet(in_channels=1, out_channels=2, depth=5, up_mode='upconv')\n","\n","    # - set the network  to 'eval' mode\n","    net.eval()\n","    # - generate a random input batch [Nx3x32x32]\n","    in_images = 1\n","    x = torch.randn((in_images, 1, 572, 572))\n","\n","    # - feed the batch through the network (forward), using CPU\n","    if not torch.cuda.is_available():\n","        print(\"running on CPU\")\n","        y = net(x)\n","\n","    # - feed the batch through the network (forward), using GPU\n","    #   hint: make sure both input and network are moved to GPU.\n","    if torch.cuda.is_available():\n","        print(\"running on GPU\")\n","        device = torch.device('cuda:0')\n","        x = x.to(device)\n","        net = net.to(device)\n","        y = net(x)\n","\n","    # - Make a nice summary table of the network using 'torchinfo'\n","    # Display the following columns: input size, output size, #params, #MACs per layer\n","    # ex. from torchinfo import summary ; summary(net, input_size=(1,3,224,224),...)\n","    # print needed for notebook mode\n","\n","    print(summary(net,\n","                  input_size=(in_images, 1, 572, 572),\n","                  col_names=[\"input_size\", \"output_size\", \"num_params\"],\n","                  col_width=15,\n","                  depth=10))\n","\n","\n","#%%\n","if __name__ == \"__main__\":\n","    main(sys.argv)\n"],"metadata":{"id":"zVEo_YuhnzVN"},"execution_count":null,"outputs":[]}]}