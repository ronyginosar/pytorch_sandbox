{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOH4qRAa2i9tFXneieRBZ3w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DO4sLYCWhILM"},"outputs":[],"source":["# Mout Google Drive\n","# https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228\n","from google.colab import drive\n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n","# %pwd %ls\n","# run github settings\n","%run /content/drive/MyDrive/CNNStanford/pytorch/pytorch_sandbox/Colab_Helper.ipynb"]},{"cell_type":"code","source":["MESSAGE = \"clean file & gitignore again\"\n","!git config --global user.email \"ronyginosar@mail.huji.ac.il\"\n","!git config --global user.name \"ronyginosar\"\n","!git add ."],"metadata":{"id":"A6ENAdliiQ9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"{MESSAGE}\"\n","!git push \"{GIT_PATH}\""],"metadata":{"id":"9QWMKhNdiTJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import sys\n","import os\n","import torchvision.transforms as transforms\n","from torchvision.datasets import CIFAR10\n","from exercises.part5_train.ex1_train_cifar import tensor_show\n","from exercises.part3_nn_modules.ex1 import Ex1Net\n","import torchvision\n","\n","batch_size = 4\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","def main(argv):\n","    \"\"\"\n","    Write your evaluation code here ...\n","    \"\"\"\n","    #Torchmetrics ??\n","    # eval vs validation??\n","    # skeleton see part 6\n","    CHECKPOINT_PATH = os.path.join(os.getcwd(), \"checkpoints\", \"latest.pt\")\n","\n","    model = Ex1Net(in_channels=[3, 32, 64, 128],\n","                 out_channels=[32, 64, 128, 256],\n","                 pools=['max', 'max', 'max', 'avg'],\n","                 num_classes=10)\n","    checkpoint = torch.load(CHECKPOINT_PATH)\n","    model.load_state_dict(checkpoint['model'])\n","    # must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference\n","    model.eval()\n","    # print(model.state_dict())\n","\n","\n","    normalize_transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    root_path = os.path.join(os.getcwd(), \"data\")  # if needed: \"exercises\", \"part5_train\"\n","    testset = CIFAR10(root=root_path, train=False, download=True, transform=normalize_transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    # see output on example from test set\n","    dataiter = iter(testloader)\n","    images, labels = next(dataiter)\n","    # print images\n","    # tensor_show(torchvision.utils.make_grid(images), is_normalized=True, one_channel=False, is_show=True)\n","    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n","    # print predictions\n","    outputs = model(images)\n","    _, predicted = torch.max(outputs, dim=1)\n","    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n","                                  for j in range(4)))\n","\n","    # prediction on entire test set:\n","    # correct = 0\n","    # total = 0\n","    correct_pred = {classname: 0 for classname in classes}\n","    total_pred = {classname: 0 for classname in classes}\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for (images, labels) in testloader:\n","            # calculate outputs by running images through the network\n","            outputs = model(images)\n","            # the class with the highest energy is what we choose as prediction\n","            _, predicted = torch.max(outputs, 1)\n","\n","            # total += labels.size(0)\n","            # correct += (predicted == labels).sum().item()\n","\n","            # collect the correct predictions for each class\n","            for label, prediction in zip(labels, predicted):\n","                if label == prediction:\n","                    correct_pred[classes[label]] += 1\n","                total_pred[classes[label]] += 1\n","\n","    # print accuracy for each class\n","    for classname, correct_count in correct_pred.items():\n","        accuracy = 100 * float(correct_count) / total_pred[classname]\n","        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n","\n","    # print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n","    print(f'Accuracy of the network on the overall test images: '\n","          f'{100 * sum(correct_pred.values()) // sum(total_pred.values())} %')\n","\n","if __name__ == \"__main__\":\n","    main(sys.argv[1:])"],"metadata":{"id":"AZc_eyYntBy-"},"execution_count":null,"outputs":[]}]}