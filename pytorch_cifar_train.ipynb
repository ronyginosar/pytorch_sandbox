{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJkEjvDVEqm6pOVRurJ4W4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DO4sLYCWhILM"},"outputs":[],"source":["# Mout Google Drive\n","# https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228\n","from google.colab import drive\n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n","# %pwd %ls\n","# run github settings\n","%run /content/drive/MyDrive/CNNStanford/pytorch/pytorch_sandbox/Colab_Helper.ipynb"]},{"cell_type":"code","source":["MESSAGE = \"clean file & gitignore again\"\n","!git config --global user.email \"ronyginosar@mail.huji.ac.il\"\n","!git config --global user.name \"ronyginosar\"\n","!git add ."],"metadata":{"id":"A6ENAdliiQ9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"{MESSAGE}\"\n","!git push \"{GIT_PATH}\""],"metadata":{"id":"9QWMKhNdiTJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import sys\n","import torchvision\n","from torchvision.datasets import CIFAR10\n","from exercises.part3_nn_modules.ex1 import Ex1Net\n","import torchvision.transforms as transforms\n","import os\n","# from torchinfo import summary\n","# from PIL import Image\n","import matplotlib.pyplot as plt\n","from torch.utils.tensorboard import SummaryWriter\n","import numpy as np\n","import torch.nn.functional as f\n","from datetime import datetime\n","from torch.utils.data import random_split\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","\n","num_epochs = 100\n","base_lr = 1e-4\n","batch_size = 4\n","mini_batch_print = 1000  # print every x mini-batches\n","validation_split = 0.10 # use 10% of training data as a validation set\n","# constant for classes\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","\n","def tensor_show(image_tensor, title=None, is_normalized=True, one_channel=False, is_show=False):\n","    if one_channel:\n","        image_tensor = image_tensor.mean(dim=0)\n","    if is_normalized:\n","        image_tensor = image_tensor / 2 + 0.5  # un-normalize\n","    if one_channel:\n","        plt.imshow(image_tensor.cpu(), cmap=\"Greys\")\n","    else:\n","        plt.imshow(image_tensor.permute(1, 2, 0))\n","    if title:\n","        plt.title(title)\n","    if is_show:\n","        plt.show()\n","\n","\n","# tensorboard helper functions\n","\n","def images_to_probs(data_output):\n","    \"\"\"\n","    Generates predictions and corresponding probabilities from a trained\n","    network and a list of images\n","    https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n","    \"\"\"\n","    # convert output probabilities to predicted class\n","    _, preds_tensor = torch.max(data_output, dim=1)\n","    preds = torch.squeeze(preds_tensor)\n","    return preds, [f.softmax(el, dim=0)[i].item() for i, el in zip(preds, data_output)]\n","\n","\n","def plot_classes_preds(data_output, images, labels):\n","    \"\"\"\n","    Generates matplotlib Figure using a trained network, along with images\n","    and labels from a batch, that shows the network's top prediction along\n","    with its probability, alongside the actual label, coloring this\n","    information based on whether the prediction was correct or not.\n","    Uses the \"images_to_probs\" function.\n","    https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n","    \"\"\"\n","    preds, probs = images_to_probs(data_output)\n","    # plot the images in the batch, along with predicted and true labels\n","    # fig = plt.figure(figsize=(12, 48))\n","    fig = plt.figure(figsize=(16, 8))\n","    for idx in np.arange(4):\n","        ax = fig.add_subplot(1, 4, idx + 1, xticks=[], yticks=[])\n","        tensor_show(images[idx], is_normalized=True, one_channel=True)\n","        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n","            classes[preds[idx]],\n","            probs[idx] * 100.0,\n","            classes[labels[idx]]),\n","            color=(\"green\" if preds[idx] == labels[idx].item() else \"red\"))\n","    return fig\n","\n","\n","def print_batch_statistics(epoch, running_loss, writer, loader_size, data_output, data, labels, i=0, mini_batch=False, training=True):\n","    # TODO more metrics\n","    if mini_batch: div_factor = mini_batch_print\n","    else: div_factor = loader_size # for validation epoch, entire epoch size is the divider size\n","\n","    if training:\n","        print(f'[{epoch + 1}, {i + 1:5d}] '\n","              f'loss: {running_loss / div_factor:.3f}')  # running loss in accordance to minibatchprint size\n","        # log the running loss\n","        writer.add_scalar('training loss',\n","                          running_loss / div_factor,  # running loss in accordance to minibatchprint size\n","                          epoch * loader_size + i)\n","        # log a plt Figure showing the model's predictions on a random mini-batch\n","        global_step = epoch * loader_size + i\n","        if i==0: global_step=5  # for validation epoch, mark the figure\n","        writer.add_figure('predictions vs. actuals',\n","                          plot_classes_preds(data_output, data, labels),\n","                          global_step=global_step)\n","        writer.add_image(f'images', torchvision.utils.make_grid(data), 0)\n","    else:\n","        print(f'validation epoch [{epoch + 1}] '\n","              f'validation loss: {running_loss / div_factor:.3f}')  # running loss in accordance to minibatchprint size\n","        # log the running loss\n","        writer.add_scalar('validation loss',\n","                          running_loss / div_factor,  # running loss in accordance to batch size\n","                          epoch * loader_size + i)\n","        # log a plt Figure showing the model's predictions on a validation batch\n","        writer.add_figure('validation predictions vs. actuals',\n","                          plot_classes_preds(data_output, data, labels),\n","                          global_step=epoch * loader_size)\n","        writer.add_image(f'validation images', torchvision.utils.make_grid(data), 0)  # {i}\n","        print(f\"validation accuracy {accuracy(data_output, labels)}\")\n","\n","\n","def accuracy(data_output, labels):\n","    # preds, _ = images_to_probs(data_output)\n","    # acc = torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","    _, preds = torch.max(data_output, dim=1)\n","    acc = torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","    # TODO - verify the print is right\n","    return acc\n","\n","def train_epoch(net, train_loader, device, optimizer, calc_loss, epoch, writer):\n","    running_loss = 0.0\n","    net.train()  # set net to train mode\n","    for i, (data, labels) in enumerate(train_loader):\n","    # for (data, labels) in train_loader:\n","        # print(f 'mini epoch {i}')\n","        data = data.to(device)  # move to GPU if available\n","        labels = labels.to(device)  # move to GPU if available\n","        optimizer.zero_grad()  # zero gradients so won't accumulate\n","        output = net(data)\n","        loss = calc_loss(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item() * data.size(0) # loss.item() is not the loss for an entire mini-batch, it is devided by the size of the minibatch\n","        # print every x mini-batches\n","        if i % mini_batch_print == (mini_batch_print - 1):\n","            print_batch_statistics(epoch, running_loss, writer, len(train_loader), output, data, labels, i, mini_batch=True, training=True)\n","            running_loss = 0.0\n","\n","    epoch_loss = running_loss / len(train_loader) # loss averaged across all examples for the current epoch\n","    return epoch_loss\n","\n","\n","def validation_epoch(net, validation_loader, device, calc_loss, epoch, writer):\n","    running_loss = 0.0\n","    net.eval()  # set net to train mode\n","    with torch.no_grad(): # we don't want to calculate gradients, just validation\n","        for (data, labels) in validation_loader:\n","            data = data.to(device)  # move to GPU if available\n","            labels = labels.to(device)  # move to GPU if available\n","            output = net(data)\n","            loss = calc_loss(output, labels)\n","            running_loss += loss.item() * data.size(0)\n","    print_batch_statistics(epoch, running_loss, writer, len(validation_loader), output, data, labels, training=False)\n","    epoch_loss = running_loss / len(validation_loader)   # loss averaged across all examples for the current epoch\n","    return epoch_loss\n","\n","\n","def load_checkpoint(path, net, optimizer, scheduler):\n","    cp = torch.load(path)\n","    net.load_state_dict(cp['model'])\n","    optimizer.load_state_dict(cp['optimizer'])\n","    scheduler.load_state_dict(cp['scheduler'])\n","    return cp['epoch']\n","\n","\n","def main(argv):\n","    # tensorboard\n","    current_run = f\"{datetime.now():%Y.%m.%d_%H.%M}\"\n","    # writer = SummaryWriter(os.path.join(os.getcwd(), \"exercises\", \"part5_train\", \"runs\", current_run))\n","    writer = SummaryWriter(os.path.join(os.getcwd(), \"runs\", current_run))\n","\n","    # Specify a path for saving the model\n","    CHECKPOINT_PATH = os.path.join(os.getcwd(), \"checkpoints\", \"latest.pt\")\n","    resume = True\n","    start_epoch = 0\n","    # todo add load from init net\n","\n","    # DS helper\n","    # A function/transform that takes in an PIL image and returns a transformed version\n","    normalize_transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    # Define dataset\n","    # CIFAR10 returns (image, target) where target is index of the target class.\n","    # to access one image: im, c = train_data[idx]\n","    # train_data, val_data = CIFAR10(root='./data', download=True, transform=transform)\n","    # or just training DS:\n","    # root_path = os.path.join(os.getcwd(), \"exercises\", \"part5_train\", \"data\")  # if needed: \"exercises\", \"part5_train\"\n","    root_path = os.path.join(os.getcwd(), \"data\")  # if needed: \"exercises\", \"part5_train\"\n","    train_data = CIFAR10(root=root_path, transform=normalize_transform, train=True)  # , download=True)\n","    # print(f' ROOT PRINT {root_path}')\n","\n","    # validation-training split\n","    rand_seed = torch.random.get_rng_state()\n","    torch.manual_seed(43)  # momentary seed to get the same validation set each time\n","    val_size = int(len(train_data)*validation_split) # x% of training set\n","    train_size = int(len(train_data)*(1-validation_split))\n","    train_ds, val_ds = random_split(train_data, [train_size, val_size])\n","    torch.random.set_rng_state(rand_seed)\n","\n","    # Define DataLoader for training\n","    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n","                                               num_workers=4, pin_memory=True)  # improve speed when using GPU\n","\n","    # Define DataLoader for validation\n","    validation_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size,\n","                                               num_workers=4, pin_memory=True)\n","\n","    # Define the network, ex3.1\n","    net = Ex1Net(in_channels=[3, 32, 64, 128],\n","                 out_channels=[32, 64, 128, 256],\n","                 pools=['max', 'max', 'max', 'avg'],\n","                 num_classes=10)\n","    # print(\"built net\")\n","    # print summary\n","    # print(summary(net,\n","    #               input_size=(data.shape),\n","    #               col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n","    #               col_width=15,\n","    #               depth=10))\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    if (device==\"cuda:0\"):\n","        print(\"GPU Check: Using GPU CUDA\")\n","    else:\n","        print(\"GPU Check: Using CPU\")\n","    net = net.to(device)  # move entire net to GPU if available (instead of forcing it by .cuda())\n","    # TODO build net on GPU instead of moving\n","\n","    # Define optimizer\n","    optimizer = torch.optim.Adam(net.parameters(), lr=base_lr)\n","\n","    # LR scheduler\n","    lr_scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=20)\n","\n","    # Define Loss\n","    calc_loss = torch.nn.CrossEntropyLoss()\n","\n","    # todo save initial net upon flag and load it\n","    if resume and os.path.exists(CHECKPOINT_PATH):\n","        print(\"loading last epoch\")\n","        last_epoch = load_checkpoint(CHECKPOINT_PATH, net, optimizer, lr_scheduler)\n","        start_epoch = last_epoch + 1\n","\n","    # Actual Training\n","    for epoch in range(start_epoch, num_epochs):\n","        print(\"starting training\")\n","        training_loss = train_epoch(net, train_loader, device, optimizer, calc_loss, epoch, writer)\n","        validation_loss = validation_epoch(net, validation_loader, device, calc_loss, epoch, writer)\n","        # adjust schedule according to validation loss\n","        lr_scheduler.step(validation_loss)\n","        # Save\n","        # todo function for save\n","        save_dict = { 'epoch': epoch,\n","                      'model': net.state_dict(),\n","                      'optimizer': optimizer.state_dict(),\n","                      'scheduler': lr_scheduler.state_dict(),\n","                      'loss': training_loss}\n","        torch.save(save_dict, CHECKPOINT_PATH)  # saves net.state_dict to path\n","        print(f'Finished epoch {epoch}, saved state')\n","        # todo Save & update the best model (i.e. when validation loss reaches a new minimum)\n","\n","    writer.close()\n","    print('Finished Training')\n","\n","\n","if __name__ == \"__main__\":\n","    main(sys.argv[1:])\n","\n","# %%\n","# # get some random training images\n","# dataiter = iter(train_loader)\n","# images, labels = next(dataiter)\n","# # show images\n","# tensor_show(torchvision.utils.make_grid(images), isNormalized = True)\n"],"metadata":{"id":"3EO5cEbctHnf"},"execution_count":null,"outputs":[]}]}